{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719c3076-f7af-4c9b-bbd3-4bd32271765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# This tutorial is from Devseed's Random Forest Model for Crop Type and LC\n",
    "# http://devseed.com/sat-ml-training/Randomforest_cropmapping-with_GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b01d4b01-42fe-4dd2-b936-be3e3e906af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path as op\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import shapely as shp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.features import rasterize\n",
    "from rasterstats.io import bounds_window\n",
    "import rasterstats\n",
    "import folium\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble._forest import ForestClassifier, ForestRegressor\n",
    "import lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5408cc6a-fd4e-44f6-93f9-4abd16b7daa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parcel_id_year</th>\n",
       "      <th>volume_mean</th>\n",
       "      <th>iu30_mean</th>\n",
       "      <th>basal_mean</th>\n",
       "      <th>height_mean</th>\n",
       "      <th>dq_mean</th>\n",
       "      <th>basal_tot_mean</th>\n",
       "      <th>dbh_mean</th>\n",
       "      <th>species</th>\n",
       "      <th>inv_year</th>\n",
       "      <th>age_2019</th>\n",
       "      <th>species.1</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>414642</td>\n",
       "      <td>20110-538658-2016</td>\n",
       "      <td>420.940000</td>\n",
       "      <td>412.500000</td>\n",
       "      <td>59.540000</td>\n",
       "      <td>19.040000</td>\n",
       "      <td>28.380000</td>\n",
       "      <td>59.5</td>\n",
       "      <td>27.1</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2016</td>\n",
       "      <td>23</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.578048</td>\n",
       "      <td>-37.813762</td>\n",
       "      <td>POINT (-73.57805 -37.81376)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>434810</td>\n",
       "      <td>20246-535806-2014</td>\n",
       "      <td>540.743750</td>\n",
       "      <td>528.747917</td>\n",
       "      <td>68.616667</td>\n",
       "      <td>22.635417</td>\n",
       "      <td>29.139583</td>\n",
       "      <td>68.6</td>\n",
       "      <td>27.4</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.570374</td>\n",
       "      <td>-37.821603</td>\n",
       "      <td>POINT (-73.57037 -37.82160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>434789</td>\n",
       "      <td>20246-492833-2004</td>\n",
       "      <td>81.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.658333</td>\n",
       "      <td>9.483333</td>\n",
       "      <td>16.675000</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2004</td>\n",
       "      <td>25</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.570706</td>\n",
       "      <td>-37.821013</td>\n",
       "      <td>POINT (-73.57071 -37.82101)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>434805</td>\n",
       "      <td>20246-535806-2014</td>\n",
       "      <td>540.743750</td>\n",
       "      <td>528.747917</td>\n",
       "      <td>68.616667</td>\n",
       "      <td>22.635417</td>\n",
       "      <td>29.139583</td>\n",
       "      <td>68.6</td>\n",
       "      <td>27.4</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.571527</td>\n",
       "      <td>-37.820716</td>\n",
       "      <td>POINT (-73.57153 -37.82072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434836</td>\n",
       "      <td>20246-535806-2014</td>\n",
       "      <td>540.743750</td>\n",
       "      <td>528.747917</td>\n",
       "      <td>68.616667</td>\n",
       "      <td>22.635417</td>\n",
       "      <td>29.139583</td>\n",
       "      <td>68.6</td>\n",
       "      <td>27.4</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.570409</td>\n",
       "      <td>-37.819801</td>\n",
       "      <td>POINT (-73.57041 -37.81980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231788</th>\n",
       "      <td>814524</td>\n",
       "      <td>80003-537535-2016</td>\n",
       "      <td>68.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.050000</td>\n",
       "      <td>10.807500</td>\n",
       "      <td>13.627500</td>\n",
       "      <td>20.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.026291</td>\n",
       "      <td>-37.027302</td>\n",
       "      <td>POINT (-73.02629 -37.02730)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231789</th>\n",
       "      <td>815155</td>\n",
       "      <td>80003-542106-2017</td>\n",
       "      <td>141.607463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.789552</td>\n",
       "      <td>14.262687</td>\n",
       "      <td>16.174627</td>\n",
       "      <td>28.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.026445</td>\n",
       "      <td>-37.026995</td>\n",
       "      <td>POINT (-73.02644 -37.02699)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231790</th>\n",
       "      <td>814319</td>\n",
       "      <td>80003-531921-2014</td>\n",
       "      <td>23.376768</td>\n",
       "      <td>17.268687</td>\n",
       "      <td>12.346465</td>\n",
       "      <td>7.896970</td>\n",
       "      <td>10.580808</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.022386</td>\n",
       "      <td>-37.026953</td>\n",
       "      <td>POINT (-73.02239 -37.02695)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231791</th>\n",
       "      <td>815085</td>\n",
       "      <td>80003-542105-2017</td>\n",
       "      <td>130.437912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.651099</td>\n",
       "      <td>14.205495</td>\n",
       "      <td>16.036813</td>\n",
       "      <td>26.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.023507</td>\n",
       "      <td>-37.026946</td>\n",
       "      <td>POINT (-73.02351 -37.02695)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231792</th>\n",
       "      <td>813712</td>\n",
       "      <td>80003-509815-2007</td>\n",
       "      <td>381.474138</td>\n",
       "      <td>378.181034</td>\n",
       "      <td>37.243103</td>\n",
       "      <td>27.503448</td>\n",
       "      <td>37.931034</td>\n",
       "      <td>37.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>2007</td>\n",
       "      <td>35</td>\n",
       "      <td>PINUS</td>\n",
       "      <td>-73.023271</td>\n",
       "      <td>-37.026529</td>\n",
       "      <td>POINT (-73.02327 -37.02653)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179988 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     parcel_id_year  volume_mean   iu30_mean  basal_mean  \\\n",
       "0           414642  20110-538658-2016   420.940000  412.500000   59.540000   \n",
       "1           434810  20246-535806-2014   540.743750  528.747917   68.616667   \n",
       "2           434789  20246-492833-2004    81.375000    0.000000   22.658333   \n",
       "3           434805  20246-535806-2014   540.743750  528.747917   68.616667   \n",
       "4           434836  20246-535806-2014   540.743750  528.747917   68.616667   \n",
       "...            ...                ...          ...         ...         ...   \n",
       "231788      814524  80003-537535-2016    68.980000    0.000000   20.050000   \n",
       "231789      815155  80003-542106-2017   141.607463    0.000000   28.789552   \n",
       "231790      814319  80003-531921-2014    23.376768   17.268687   12.346465   \n",
       "231791      815085  80003-542105-2017   130.437912    0.000000   26.651099   \n",
       "231792      813712  80003-509815-2007   381.474138  378.181034   37.243103   \n",
       "\n",
       "        height_mean    dq_mean  basal_tot_mean  dbh_mean species  inv_year  \\\n",
       "0         19.040000  28.380000            59.5      27.1   PINUS      2016   \n",
       "1         22.635417  29.139583            68.6      27.4   PINUS      2014   \n",
       "2          9.483333  16.675000            22.6       0.0   PINUS      2004   \n",
       "3         22.635417  29.139583            68.6      27.4   PINUS      2014   \n",
       "4         22.635417  29.139583            68.6      27.4   PINUS      2014   \n",
       "...             ...        ...             ...       ...     ...       ...   \n",
       "231788    10.807500  13.627500            20.1      13.1   PINUS      2016   \n",
       "231789    14.262687  16.174627            28.8      15.6   PINUS      2017   \n",
       "231790     7.896970  10.580808            12.5      10.3   PINUS      2014   \n",
       "231791    14.205495  16.036813            26.7      15.5   PINUS      2017   \n",
       "231792    27.503448  37.931034            37.2      36.0   PINUS      2007   \n",
       "\n",
       "        age_2019 species.1        lon        lat                     geometry  \n",
       "0             23     PINUS -73.578048 -37.813762  POINT (-73.57805 -37.81376)  \n",
       "1             25     PINUS -73.570374 -37.821603  POINT (-73.57037 -37.82160)  \n",
       "2             25     PINUS -73.570706 -37.821013  POINT (-73.57071 -37.82101)  \n",
       "3             25     PINUS -73.571527 -37.820716  POINT (-73.57153 -37.82072)  \n",
       "4             25     PINUS -73.570409 -37.819801  POINT (-73.57041 -37.81980)  \n",
       "...          ...       ...        ...        ...                          ...  \n",
       "231788        10     PINUS -73.026291 -37.027302  POINT (-73.02629 -37.02730)  \n",
       "231789        10     PINUS -73.026445 -37.026995  POINT (-73.02644 -37.02699)  \n",
       "231790        10     PINUS -73.022386 -37.026953  POINT (-73.02239 -37.02695)  \n",
       "231791        10     PINUS -73.023507 -37.026946  POINT (-73.02351 -37.02695)  \n",
       "231792        35     PINUS -73.023271 -37.026529  POINT (-73.02327 -37.02653)  \n",
       "\n",
       "[179988 rows x 16 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d464e50c-5373-4f6e-9d98-4f7d91888076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training_vectors = gpd.read_file('../data/training/2019_arauco_lcTraining.shp')\n",
    "# bbox = training_vectors.total_bounds\n",
    "# center = shp.geometry.box(bbox[0], bbox[1], bbox[2], bbox[3]).centroid\n",
    "\n",
    "# # show the 1st 5 lines\n",
    "# training_vectors.head()\n",
    "\n",
    "# # find all unique values of training data names to use as classes\n",
    "# classes = np.unique(training_vectors['class'])\n",
    "# classes\n",
    "\n",
    "# # create a dictionary to convert class names into integers for modeling\n",
    "# class_dict = dict(zip(classes, range(len(classes))))\n",
    "# class_dict \n",
    "\n",
    "# raster_file = '/Users/brian.h.lee/Desktop/ch3/chile_forests/data/merged/2019_study_allrs10b.tif'\n",
    "\n",
    "# # raster information\n",
    "\n",
    "# ##If you want to read the data directly from the shared folder, uncomment the following line.\n",
    "# # raster_file = '/content/drive/Shared drives/servir-sat-ml/data/Trans_nzoia_2019_05-02.tif'\n",
    "\n",
    "\n",
    "# # a custom function for getting each value from the raster\n",
    "# def all_values(x):\n",
    "#     return x\n",
    "\n",
    "# # this larger cell reads data from a raster file for each training vector\n",
    "# X_raw = []\n",
    "# y_raw = []\n",
    "# with rasterio.open(raster_file, 'r') as src:\n",
    "#     for (label, geom) in zip(training_vectors['class'], training_vectors['geometry']):\n",
    "        \n",
    "#         # read the raster data matching the geometry bounds\n",
    "#         window = bounds_window(geom.bounds, src.transform)\n",
    "#         # store our window information\n",
    "#         window_affine = src.window_transform(window)\n",
    "#         fsrc = src.read(window=window)\n",
    "#         # rasterize the geometry into the larger shape and affine\n",
    "#         mask = rasterize(\n",
    "#             [(geom, 1)],\n",
    "#             out_shape=fsrc.shape[1:],\n",
    "#             transform=window_affine,\n",
    "#             fill=0,\n",
    "#             dtype='uint8',\n",
    "#             all_touched=True\n",
    "#         ).astype(bool)\n",
    "        \n",
    "#         # for each label pixel (places where the mask is true)\n",
    "#         label_pixels = np.argwhere(mask)\n",
    "        \n",
    "#         for (row, col) in label_pixels:\n",
    "#             # add a pixel of data to X\n",
    "#             data = fsrc[:,row,col]\n",
    "#             one_x = np.nan_to_num(data, nan=1e-3)\n",
    "#             X_raw.append(one_x)\n",
    "#             # add the label to y\n",
    "#             y_raw.append(class_dict[label])\n",
    "            \n",
    "# # convert the training data lists into the appropriate numpy array shape and format for scikit-learn\n",
    "# X = np.array(X_raw)\n",
    "# y = np.array(y_raw)\n",
    "# (X.shape, y.shape)\n",
    "\n",
    "# # helper function for calculating ND*I indices (bands in the final dimension)\n",
    "# def band_index(arr, a, b):\n",
    "#     return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1)\n",
    "\n",
    "# ndvi = band_index(X, 5, 4)\n",
    "# # ndwi = band_index(X, 1, 3)\n",
    "\n",
    "# X = np.concatenate([X, ndvi], axis=1)\n",
    "# X.shape\n",
    "\n",
    "# # split the data into test and train sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # calculate class weights to allow for training on inbalanced training samples\n",
    "# labels, counts = np.unique(y_train, return_counts=True)\n",
    "# class_weight_dict = dict(zip(labels, 1 / counts))\n",
    "# class_weight_dict\n",
    "\n",
    "# # initialize a RandomForestClassifier\n",
    "# clf = RandomForestClassifier(\n",
    "#     n_estimators=200,\n",
    "#     class_weight=class_weight_dict,\n",
    "#     max_depth=6,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1,\n",
    "#     random_state=0)\n",
    "\n",
    "# # fit the model to the data (training)\n",
    "# clf.fit(X, y)\n",
    "\n",
    "# # predict on X_test to evaluate the model\n",
    "# preds = clf.predict(X_test)\n",
    "# cm = confusion_matrix(y_test, preds, labels=labels)\n",
    "\n",
    "# root_dir = '/Users/brian.h.lee/Desktop/ch3/chile_forests/models'\n",
    "\n",
    "# # (optional) save the trained model as python pickle file\n",
    "# model_name = op.join(root_dir,'random_forest_2019_lc.sav')\n",
    "# with open(model_name, 'wb') as modelfile:\n",
    "#     pickle.dump(clf, modelfile)\n",
    "    \n",
    "#     # plot the confusion matrix\n",
    "# %matplotlib inline\n",
    "# cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "# ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# # We want to show all ticks...\n",
    "# ax.set(xticks=np.arange(cm.shape[1]),\n",
    "#        yticks=np.arange(cm.shape[0]),\n",
    "#        # ... and label them with the respective list entries\n",
    "#        xticklabels=classes, yticklabels=classes,\n",
    "#        title='Normalized Confusion Matrix',\n",
    "#        ylabel='True label',\n",
    "#        xlabel='Predicted label')\n",
    "\n",
    "# # Rotate the tick labels and set their alignment.\n",
    "# plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#          rotation_mode=\"anchor\")\n",
    "\n",
    "# # Loop over data dimensions and create text annotations.\n",
    "# fmt = '.2f'\n",
    "# thresh = cm.max() / 2.\n",
    "# for i in range(cm.shape[0]):\n",
    "#     for j in range(cm.shape[1]):\n",
    "#         ax.text(j, i, format(cm[i, j], fmt),\n",
    "#                 ha=\"center\", va=\"center\",\n",
    "#                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "# fig.tight_layout()\n",
    "\n",
    "# importances = clf.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "\n",
    "# band_names = ['ALOSHH', 'ALOSHHHV', 'ALOSHV', 'S2BLUE', 'S2GREEN', 'S2RED', 'S1VH', 'S1VV', 'S1VVVH', 'S2NIR', 'NDVI']\n",
    "\n",
    "# forest_importances = pd.Series(importances, index=band_names)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "# ax.set_title(\"Feature importances using MDI\")\n",
    "# ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "# fig.tight_layout()\n",
    "\n",
    "# # predict again with the tree interpreter to see how much each band contributes to the classification\n",
    "# sample = 100\n",
    "# prediction, bias, contributions = ti.predict(clf, X_test[:sample])\n",
    "# c = np.sum(contributions, axis=0)\n",
    "\n",
    "# # plot the contributions\n",
    "# band_names = ['ALOSHH', 'ALOSHHHV', 'ALOSHV', 'S2BLUE', 'S2GREEN', 'S2RED', 'S1VH', 'S1VV', 'S1VVVH', 'S2NIR', 'NDVI']\n",
    "\n",
    "# gdf = gpd.GeoDataFrame(c, columns=classes, index=band_names)\n",
    "# gdf.style.background_gradient(cmap='viridis')\n",
    "\n",
    "# # in this case, we predict over the entire input image\n",
    "# # (only small portions were used for training)\n",
    "# new_image = raster_file\n",
    "\n",
    "# # specify the output\n",
    "# output_image = op.join(root_dir, \"classification.tif\")\n",
    "\n",
    "# with rasterio.open(new_image, 'r') as src:\n",
    "#     profile = src.profile\n",
    "#     profile.update(\n",
    "#         dtype=rasterio.uint8,\n",
    "#         count=1,\n",
    "#     )\n",
    "\n",
    "#     with rasterio.open(output_image, 'w', **profile) as dst:\n",
    "\n",
    "        \n",
    "#         # perform prediction on each small image patch to minimize required memory\n",
    "#         patch_size = 500\n",
    "\n",
    "#         for i in range((src.shape[0] // patch_size) + 1):\n",
    "#             for j in range((src.shape[1] // patch_size) + 1):\n",
    "#                 # define the pixels to read (and write) with rasterio windows reading\n",
    "#                 window = rasterio.windows.Window(\n",
    "#                     j * patch_size,\n",
    "#                     i * patch_size,\n",
    "#                     # don't read past the image bounds\n",
    "#                     min(patch_size, src.shape[1] - j * patch_size),\n",
    "#                     min(patch_size, src.shape[0] - i * patch_size))\n",
    "                \n",
    "#                 # read the image into the proper format\n",
    "#                 data = src.read(window=window)\n",
    "                \n",
    "#                 # adding indices if necessary\n",
    "#                 img_swp = np.moveaxis(data, 0, 2)\n",
    "#                 img_flat = img_swp.reshape(-1, img_swp.shape[-1])\n",
    "\n",
    "#                 img_ndvi = band_index(img_flat, 5, 4)\n",
    "#                 img_ndwi = band_index(img_flat, 1, 3)\n",
    "\n",
    "#                 img_w_ind = np.concatenate([img_flat, img_ndvi, img_ndwi], axis=1)\n",
    "\n",
    "#                 # remove no data values, store the indices for later use\n",
    "#                 m = np.ma.masked_invalid(img_w_ind)\n",
    "#                 to_predict = img_w_ind[~m.mask].reshape(-1, img_w_ind.shape[-1])\n",
    "\n",
    "#                 # skip empty inputs\n",
    "#                 if not len(to_predict):\n",
    "#                     continue\n",
    "#                 # predict\n",
    "#                 img_preds = clf.predict(to_predict)\n",
    "\n",
    "#                 # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity)\n",
    "#                 # makes the assumption that all bands have identical no-data value arrangements\n",
    "#                 output = np.zeros(img_flat.shape[0])\n",
    "#                 output[~m.mask[:, 0]] = img_preds.flatten()\n",
    "#                 # resize to the original image dimensions\n",
    "#                 output = output.reshape(*img_swp.shape[:-1])\n",
    "\n",
    "#                 # create our final mask\n",
    "#                 mask = (~m.mask[:, 0]).reshape(*img_swp.shape[:-1])\n",
    "\n",
    "#                 # write to the final files\n",
    "#                 dst.write(output.astype(rasterio.uint8), 1, window=window)\n",
    "#                 dst.write_mask(mask, window=window)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c13f6d8-0980-4a08-9530-ffbabda10ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianlee/opt/anaconda3/envs/chile_forest/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/brianlee/opt/anaconda3/envs/chile_forest/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "os.getcwd()\n",
    "os.chdir('../models/rf/')\n",
    "loaded_model = pickle.load(open('random_forest_2019_lc.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac52960-35fa-4dc7-920a-84bce7a60a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = '/Users/brianlee/Desktop/ch3/chile_forests/data/merged/samples/input'\n",
    "output_directory = '/Users/brianlee/Desktop/ch3/chile_forests/data/merged/samples/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88c59df-ce23-44b0-baee-5af2615d3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c75496d-1d00-4278-afc1-e8946dfaf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the output\n",
    "output_image = op.join(output_directory, new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19043f1a-58f9-4ba5-abe9-6e8ea6c18995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_index(arr, a, b):\n",
    "    return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f12ec74-1772-4579-8656-a0b6132b4621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:    0.9s finished\n",
      "/var/folders/dx/35d3rjys675ftkqgrd2j85lc0000gn/T/ipykernel_62005/3126048752.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1)\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:    3.7s finished\n",
      "/var/folders/dx/35d3rjys675ftkqgrd2j85lc0000gn/T/ipykernel_62005/3126048752.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1)\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:    7.4s finished\n",
      "/var/folders/dx/35d3rjys675ftkqgrd2j85lc0000gn/T/ipykernel_62005/3126048752.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1)\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:    4.1s finished\n",
      "/var/folders/dx/35d3rjys675ftkqgrd2j85lc0000gn/T/ipykernel_62005/3126048752.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1)\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:    6.2s finished\n",
      "/var/folders/dx/35d3rjys675ftkqgrd2j85lc0000gn/T/ipykernel_62005/3126048752.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1)\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=10)]: Done 200 out of 200 | elapsed:   15.4s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith ('.tif'):\n",
    "        try:\n",
    "            new_image = filename\n",
    "\n",
    "            # specify the output\n",
    "            output_image = op.join(output_directory, new_image)\n",
    "\n",
    "            with rio.open(new_image, 'r') as src:\n",
    "                profile = src.profile\n",
    "                profile.update(\n",
    "                    dtype=rio.uint8,\n",
    "                    count=1,\n",
    "                )\n",
    "\n",
    "                with rio.open(output_image, 'w', **profile) as dst:\n",
    "\n",
    "\n",
    "            #         # perform prediction on each small image patch to minimize required memory\n",
    "            #         patch_size = 500\n",
    "\n",
    "            #         for i in range((src.shape[0] // patch_size) + 1):\n",
    "            #             for j in range((src.shape[1] // patch_size) + 1):\n",
    "            #                 # define the pixels to read (and write) with rasterio windows reading\n",
    "            #                 window = rio.windows.Window(\n",
    "            #                     j * patch_size,\n",
    "            #                     i * patch_size,\n",
    "            #                     # don't read past the image bounds\n",
    "            #                     min(patch_size, src.shape[1] - j * patch_size),\n",
    "            #                     min(patch_size, src.shape[0] - i * patch_size))\n",
    "\n",
    "                            # read the image into the proper format\n",
    "                            data = src.read()\n",
    "\n",
    "                            new_data = np.nan_to_num(data, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "                            # new_data = to_numpy(df)\n",
    "\n",
    "                            # adding indices if necessary\n",
    "                            img_swp = np.moveaxis(new_data, 0, 2)\n",
    "                            img_flat = img_swp.reshape(-1, img_swp.shape[-1])\n",
    "\n",
    "                            img_ndvi = band_index(img_flat, 9, 6)\n",
    "                            img_ndvi = np.nan_to_num(img_ndvi, copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "                            # img_ndwi = band_index(img_flat, 9, 5)\n",
    "\n",
    "                            img_w_ind = np.concatenate([img_flat, img_ndvi], axis=1)\n",
    "\n",
    "                            # remove no data values, store the indices for later use\n",
    "                            # m = np.ma.masked_invalid(img_w_ind)\n",
    "                            to_predict = img_w_ind.reshape(-1, img_w_ind.shape[-1])\n",
    "\n",
    "                            # # skip empty inputs\n",
    "                            # if not len(to_predict):\n",
    "                            #     continue\n",
    "                            # predict\n",
    "                            img_preds = loaded_model.predict(to_predict)\n",
    "\n",
    "                            # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity)\n",
    "                            # makes the assumption that all bands have identical no-data value arrangements\n",
    "                            output = np.zeros(img_flat.shape[0])\n",
    "                            output = img_preds.flatten()\n",
    "                            # resize to the original image dimensions\n",
    "                            output = output.reshape(*img_swp.shape[:-1])\n",
    "\n",
    "                            # create our final mask\n",
    "                            # mask = (~m.mask[:, 0]).reshape(*img_swp.shape[:-1])\n",
    "\n",
    "                            # write to the final files\n",
    "                            dst.write(output.astype(rio.uint8), 1)\n",
    "                            # dst.write_mask(mask, window=window)\n",
    "                            \n",
    "        except:\n",
    "            print(new_image)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57fe84d-c69a-4887-a7b4-90807c41afca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chile_forest",
   "language": "python",
   "name": "chile_forest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
